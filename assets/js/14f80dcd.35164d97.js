"use strict";(self.webpackChunkllamanator_docs=self.webpackChunkllamanator_docs||[]).push([[975],{6327:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>r,contentTitle:()=>t,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>d});var o=l(4848),i=l(8453);const s={sidebar_position:2},t="Deploy on Linux",a={id:"deploying-llamanator/llamanator-bash/deploy-on-linux",title:"Deploy on Linux",description:"Security",source:"@site/docs/deploying-llamanator/llamanator-bash/deploy-on-linux.md",sourceDirName:"deploying-llamanator/llamanator-bash",slug:"/deploying-llamanator/llamanator-bash/deploy-on-linux",permalink:"/docs/deploying-llamanator/llamanator-bash/deploy-on-linux",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/deploying-llamanator/llamanator-bash/deploy-on-linux.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Llamanator Bash",permalink:"/docs/category/llamanator-bash"},next:{title:"Deploy on Mac",permalink:"/docs/deploying-llamanator/llamanator-bash/deploy-on-mac"}},r={},d=[{value:"Security",id:"security",level:2},{value:"Tools and Models Included",id:"tools-and-models-included",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Docker and Docker Compose",id:"install-docker-and-docker-compose",level:2},{value:"Using Your Own TLS Certificates",id:"using-your-own-tls-certificates",level:2},{value:"Option 1 - Automatic Self Signed",id:"option-1---automatic-self-signed",level:3},{value:"Option 2 - User Provided",id:"option-2---user-provided",level:3},{value:"Install Llamanator Bash on Linux",id:"install-llamanator-bash-on-linux",level:2},{value:".env File Options",id:"env-file-options",level:2},{value:"Uninstall Llamanator Bash",id:"uninstall-llamanator-bash",level:2},{value:"Restarting Llamanator Bash",id:"restarting-llamanator-bash",level:2},{value:"Note about Ollama",id:"note-about-ollama",level:2},{value:"Linux",id:"linux",level:3},{value:"MacOS",id:"macos",level:3},{value:"Cleaning Up Docker",id:"cleaning-up-docker",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"deploy-on-linux",children:"Deploy on Linux"}),"\n",(0,o.jsx)(n.h2,{id:"security",children:"Security"}),"\n",(0,o.jsx)(n.p,{children:"This script exposes many ports and services on your system. It is recommended that you put a firewall in front of your server to only allow your IP address to access the server or run this on a private network."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"tools-and-models-included",children:"Tools and Models Included"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Tools:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://ollama.com",children:"Ollama"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://github.com/open-webui/open-webui",children:"OpenWebUI"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://github.com/n4ze3m/dialoqbase",children:"Dialoqbase"})}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"https://www.haproxy.org/",children:"HAProxy"})," running on 80/443 to route traffic to the services (Optional)"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Models (LLMs):"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Llama2"}),"\n",(0,o.jsx)(n.li,{children:"Llama3"}),"\n",(0,o.jsx)(n.li,{children:"Mistral"}),"\n",(0,o.jsx)(n.li,{children:"Nomic Embed"}),"\n",(0,o.jsx)(n.li,{children:"Codellama"}),"\n",(0,o.jsx)(n.li,{children:"Phi3"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Ubuntu 22.04"}),"\n",(0,o.jsx)(n.li,{children:"Docker and Docker Compose"}),"\n",(0,o.jsx)(n.li,{children:"Nvidia GPU (if you want to run the Ollama GPU service)"}),"\n",(0,o.jsx)(n.li,{children:"Recommended 16vCPU and 32GB RAM (depending on services you want to run)"}),"\n",(0,o.jsx)(n.li,{children:"At least 100GB of free disk space"}),"\n",(0,o.jsx)(n.li,{children:"A user with sudo privileges (preferably passwordless sudo)"}),"\n",(0,o.jsx)(n.li,{children:"Port 80 and 443 open on your machine (if you want to use the proxy)"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"install-docker-and-docker-compose",children:"Install Docker and Docker Compose"}),"\n",(0,o.jsx)(n.p,{children:"If you system already has Docker and Docker Compose installed, you can skip this step."}),"\n",(0,o.jsxs)(n.p,{children:["Make sure that you have the Nvidia container toolkit installed on your system if you choose the GPU install. You can follow the instructions here: ",(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html",children:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"})]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Option 1"})}),"\n",(0,o.jsx)(n.p,{children:"If you want to install Docker and Docker Compose with out provided script, you can follow the instructions below:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Run the following command to install Docker: ",(0,o.jsx)(n.code,{children:"./install_docker_ubuntu.sh"})]}),"\n",(0,o.jsxs)(n.li,{children:["If you are not running as root, run the following command to add your user to the Docker group: ",(0,o.jsx)(n.code,{children:"sudo usermod -aG docker $USER"})]}),"\n",(0,o.jsx)(n.li,{children:"Logout and log back into your terminal session"}),"\n",(0,o.jsxs)(n.li,{children:["Verify that Docker is installed by running: ",(0,o.jsx)(n.code,{children:"docker --version"})]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Option 2"})}),"\n",(0,o.jsxs)(n.p,{children:["Follow the instructions from the official Docker website to install Docker and Docker Compose: ",(0,o.jsx)(n.a,{href:"https://docs.docker.com/engine/install/ubuntu/",children:"https://docs.docker.com/engine/install/ubuntu/"})]}),"\n",(0,o.jsxs)(n.p,{children:["And then install the Nvidia container toolkit if you are have an Nvidia GPU: ",(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html",children:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"using-your-own-tls-certificates",children:"Using Your Own TLS Certificates"}),"\n",(0,o.jsx)(n.p,{children:"If you intend on installing with a domain name and using the proxy, there are 2 options."}),"\n",(0,o.jsx)(n.h3,{id:"option-1---automatic-self-signed",children:"Option 1 - Automatic Self Signed"}),"\n",(0,o.jsx)(n.p,{children:"Let the script generate a self-signed certificate for you. This is the easiest option and is recommended for most users."}),"\n",(0,o.jsx)(n.h3,{id:"option-2---user-provided",children:"Option 2 - User Provided"}),"\n",(0,o.jsx)(n.p,{children:"Generate your own valid TLS certificates and use them with the proxy."}),"\n",(0,o.jsxs)(n.p,{children:["You will need to create a file called ",(0,o.jsx)(n.code,{children:"cert-bundle.pem"})," with the ",(0,o.jsx)(n.code,{children:"private.key"})," at the top followed by the ",(0,o.jsx)(n.code,{children:"fullchain.pem"})," file in a single file. Make sure all headers and footers are included like ",(0,o.jsx)(n.code,{children:"-----BEGIN-----"})," and ",(0,o.jsx)(n.code,{children:"-----END-----"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Once you have created the ",(0,o.jsx)(n.code,{children:"cert-bundle.pem"})," file, you need to place it in the ",(0,o.jsx)(n.code,{children:"./deploy/llamanator-bash/services/llamanator/haproxy/user-provided-certs"})," directory."]}),"\n",(0,o.jsxs)(n.p,{children:["Once that is done, run the install script with the ",(0,o.jsx)(n.code,{children:"--install-proxy"})," option as shown below."]}),"\n",(0,o.jsxs)(n.p,{children:["Check out the ",(0,o.jsx)(n.a,{href:"/docs/deploying-llamanator/llamanator-bash/generating-certs",children:"Generating Certs"})," page for more information on how to generate your own certificates."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"install-llamanator-bash-on-linux",children:"Install Llamanator Bash on Linux"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Clone this repo (if you haven't already): ",(0,o.jsx)(n.code,{children:"git clone https://github.com/llamanator-project/llamanator.git"})]}),"\n",(0,o.jsxs)(n.li,{children:["Change directory to the Llamanator Bash directory: ",(0,o.jsx)(n.code,{children:"cd llamanator/deploy/llamanator-bash"})]}),"\n",(0,o.jsxs)(n.li,{children:["Copy the ",(0,o.jsx)(n.code,{children:".env.example"})," file to ",(0,o.jsx)(n.code,{children:".env"}),": ",(0,o.jsx)(n.code,{children:"cp .env.example .env"})]}),"\n",(0,o.jsxs)(n.li,{children:["Edit the ",(0,o.jsx)(n.code,{children:".env"})," file to enable the services you want to run. Please review the .env instructions below for the required options."]}),"\n",(0,o.jsxs)(n.li,{children:["Run the install script:","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["To install with the Proxy on 80/443 run: ",(0,o.jsx)(n.code,{children:"sudo ./install.sh --install-proxy"})]}),"\n",(0,o.jsxs)(n.li,{children:["To install without the Proxy run: ",(0,o.jsx)(n.code,{children:"sudo ./install.sh"})]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Once complete, open the ",(0,o.jsx)(n.code,{children:"./llamanator-links.txt"})," file to access your services"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"env-file-options",children:".env File Options"}),"\n",(0,o.jsxs)(n.p,{children:["Below are the only values you should need to change in the ",(0,o.jsx)(n.code,{children:".env"})," file:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ENABLE_OLLAMACPU"}),": Set to ",(0,o.jsx)(n.code,{children:"true"})," to enable the Ollama service on a linux machine with only a CPU and no GPU (set to ",(0,o.jsx)(n.code,{children:"false"})," if running on MacOS)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ENABLE_OLLAMAGPU"}),": Set to ",(0,o.jsx)(n.code,{children:"true"})," to enable the Ollama service on a linux machine with a GPU (set to ",(0,o.jsx)(n.code,{children:"false"})," if running on MacOS)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ENABLE_OLLAMA_BASE_MODELS"}),": Set to ",(0,o.jsx)(n.code,{children:"true"})," to enable the Ollama base model downloads. This will download the base models for the Ollama service."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ENABLE_OPENWEBUI"}),": Set to ",(0,o.jsx)(n.code,{children:"true"})," to enable the OpenWebUI service"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ENABLE_DIALOQBASE"}),": Set to ",(0,o.jsx)(n.code,{children:"true"})," to enable the Dialoqbase Retrieval Augmented Generation (RAG) service"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"SERVER_IP"}),": Set this to ",(0,o.jsx)(n.code,{children:"127.0.0.1"})," if you are running on a local machine. If you are running on a server and want other machines to be able to access the services, set this to the IP address of the server."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"DOMAIN_NAME"}),": Set this to the domain name of your server if you have one (must use the install with Proxy). You will want to point the following entries to the IP address of your server in your DNS settings.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"openwebui.yourdomain.com"}),"\n",(0,o.jsx)(n.li,{children:"dialoqbase.yourdomain.com"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"OLLAMA_ENDPOINT"}),": If you want to inference against an Ollama service running on a different machine, set this to the IP address or domain name of the machine running the Ollama service. If you are running the Ollama service on the same machine, leave this as ",(0,o.jsx)(n.code,{children:"127.0.0.1"}),". Make sure that your Ollama service is exposed on the network and the machine you are running the Llamanator Bash script on can access the Ollama service."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"uninstall-llamanator-bash",children:"Uninstall Llamanator Bash"}),"\n",(0,o.jsx)(n.p,{children:"There are 2 options to remove the Llamanator project from your machine:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Just stop the services and keep the data: ",(0,o.jsx)(n.code,{children:"sudo ./uninstall.sh"})]}),"\n",(0,o.jsxs)(n.li,{children:["Stop the services and remove all data: ",(0,o.jsx)(n.code,{children:"sudo ./uninstall.sh --remove-all-data"})]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"restarting-llamanator-bash",children:"Restarting Llamanator Bash"}),"\n",(0,o.jsxs)(n.p,{children:["Regardless of the uninstall option you choose, you can restart the Llamanator project by running the ",(0,o.jsx)(n.code,{children:"./install.sh"})," script again. If the volumes are still present, the data will be re-attached to the services. If you removed the data, the services will start fresh."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"note-about-ollama",children:"Note about Ollama"}),"\n",(0,o.jsx)(n.h3,{id:"linux",children:"Linux"}),"\n",(0,o.jsxs)(n.p,{children:["The Ollama data is stored locally on the disk so you can prevent having to download the LLMs again. The data is stored on the host filesystem in the ",(0,o.jsx)(n.code,{children:"ollama_data"})," directory. If you want to remove the Ollama data, you can delete the ",(0,o.jsx)(n.code,{children:"./services/ollama/ollama_data"})," directory."]}),"\n",(0,o.jsx)(n.h3,{id:"macos",children:"MacOS"}),"\n",(0,o.jsxs)(n.p,{children:["The Ollama data is stored ",(0,o.jsx)(n.code,{children:"~/.ollama/models"})," directory. If you want to remove all Ollama data, you can delete the ",(0,o.jsx)(n.code,{children:"~/.ollama/models"})," directory."]}),"\n",(0,o.jsxs)(n.p,{children:["If you only want to remove specific LLMs, you can run ",(0,o.jsx)(n.code,{children:"ollama rm <model_name>"})," to remove the LLM from the Ollama service."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"cleaning-up-docker",children:"Cleaning Up Docker"}),"\n",(0,o.jsxs)(n.p,{children:["If you want to clean up Docker, you can run the ",(0,o.jsx)(n.code,{children:"docker system prune -a"})," command. This will remove all stopped containers, all networks not used by at least one container, all dangling images, and all build cache."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,l)=>{l.d(n,{R:()=>t,x:()=>a});var o=l(6540);const i={},s=o.createContext(i);function t(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);